"""
ì²­í‚¹ í…ŒìŠ¤íŠ¸ íŒŒì¼
split_text_with_tables í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²­í‚¹ëœ ë¬¸ì„œë“¤ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import json
import os
from datetime import datetime
from healthcare_chatbot import HealthCareChatbot

# ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œ)
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (crawlerì˜ ìƒìœ„ ë””ë ‰í† ë¦¬)
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
# ê¸°ë³¸ output ë””ë ‰í† ë¦¬ ê²½ë¡œ
DEFAULT_OUTPUT_DIR = os.path.join(PROJECT_ROOT, "output")
# ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
DEFAULT_DATA_FILE = os.path.join(DEFAULT_OUTPUT_DIR, "structured_data_ê°•ë‚¨êµ¬.json")


def test_chunking(data_file: str = None, output_dir: str = None, max_items: int = 5):
    """
    ì²­í‚¹ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        data_file: JSON ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ ê°•ë‚¨êµ¬ ë°ì´í„° ì‚¬ìš©)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì—†ìœ¼ë©´ ê¸°ë³¸ output ë””ë ‰í† ë¦¬ ì‚¬ìš©)
        max_items: í…ŒìŠ¤íŠ¸í•  ìµœëŒ€ ì•„ì´í…œ ìˆ˜ (ê¸°ë³¸ê°’: 5)
    """
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if output_dir is None:
        output_dir = DEFAULT_OUTPUT_DIR
    
    # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
    if data_file is None:
        data_file = DEFAULT_DATA_FILE
    
    if not os.path.exists(data_file):
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_file}")
        return
    
    print("\n" + "=" * 80)
    print("ğŸ§ª ì²­í‚¹ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    print(f"ë°ì´í„° íŒŒì¼: {data_file}")
    print(f"ìµœëŒ€ í…ŒìŠ¤íŠ¸ ì•„ì´í…œ ìˆ˜: {max_items}")
    
    # ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    chatbot = HealthCareChatbot(output_dir=output_dir)
    
    # ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    structured_data = chatbot.load_data(data_file)
    print(f"âœ… {len(structured_data)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
    
    # í…ŒìŠ¤íŠ¸í•  ì•„ì´í…œ ì„ íƒ
    test_items = structured_data[:max_items] if len(structured_data) >= max_items else structured_data
    
    # ì²­í‚¹ ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
    chunking_results = []
    
    print(f"\nğŸ“ ì²­í‚¹ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì´ {len(test_items)}ê°œ ì•„ì´í…œ)")
    print("=" * 80)
    
    for idx, item in enumerate(test_items, 1):
        raw_text = item.get("raw_text", "")
        if not raw_text:
            print(f"\n[{idx}] ì œëª©: {item.get('title', 'N/A')} - raw_textê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            continue
        
        print(f"\n[{idx}] ì œëª©: {item.get('title', 'N/A')}")
        print(f"    ì§€ì—­: {item.get('region', 'N/A')}")
        print(f"    ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(raw_text):,}ì")
        
        # ì²­í‚¹ ì‹¤í–‰
        chunks = chatbot.split_text_with_tables(
            raw_text,
            chunk_size=800,
            overlap=120
        )
        
        print(f"    ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")
        
        # ê° ì²­í¬ ì •ë³´ ì¶œë ¥
        chunk_details = []
        for chunk_idx, chunk in enumerate(chunks, 1):
            chunk_length = len(chunk)
            is_table = "|" in chunk and chunk.count("|") >= 2
            chunk_type = "í‘œ" if is_table else "í…ìŠ¤íŠ¸"
            
            # ì²­í¬ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 100ì)
            preview = chunk[:100].replace("\n", " ").strip()
            if len(chunk) > 100:
                preview += "..."
            
            chunk_info = {
                "chunk_number": chunk_idx,
                "type": chunk_type,
                "length": chunk_length,
                "preview": preview,
                "content": chunk
            }
            chunk_details.append(chunk_info)
            
            print(f"      ì²­í¬ {chunk_idx} ({chunk_type}): {chunk_length:,}ì - {preview}")
        
        # ê²°ê³¼ ì €ì¥
        result_item = {
            "item_id": item.get("id", ""),
            "title": item.get("title", ""),
            "region": item.get("region", ""),
            "source_url": item.get("source_url", ""),
            "original_length": len(raw_text),
            "chunk_count": len(chunks),
            "chunks": chunk_details
        }
        chunking_results.append(result_item)
    
    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(output_dir, f"chunking_test_result_{timestamp}.json")
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            "test_info": {
                "data_file": data_file,
                "test_date": datetime.now().isoformat(),
                "tested_items_count": len(test_items),
                "chunking_params": {
                    "chunk_size": 800,
                    "overlap": 120
                }
            },
            "results": chunking_results
        }, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 80)
    print("âœ… ì²­í‚¹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 80)
    print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {output_file}")
    
    # ìš”ì•½ ì •ë³´ ì¶œë ¥
    total_chunks = sum(len(r["chunks"]) for r in chunking_results)
    total_text_chunks = sum(1 for r in chunking_results for c in r["chunks"] if c["type"] == "í…ìŠ¤íŠ¸")
    total_table_chunks = sum(1 for r in chunking_results for c in r["chunks"] if c["type"] == "í‘œ")
    
    print(f"\nğŸ“Š ìš”ì•½:")
    print(f"  - í…ŒìŠ¤íŠ¸ëœ ì•„ì´í…œ ìˆ˜: {len(chunking_results)}ê°œ")
    print(f"  - ì´ ìƒì„±ëœ ì²­í¬ ìˆ˜: {total_chunks}ê°œ")
    print(f"  - í…ìŠ¤íŠ¸ ì²­í¬: {total_text_chunks}ê°œ")
    print(f"  - í‘œ ì²­í¬: {total_table_chunks}ê°œ")
    
    # ìƒì„¸ ë³´ê³ ì„œ ìƒì„± (í…ìŠ¤íŠ¸ íŒŒì¼)
    report_file = os.path.join(output_dir, f"chunking_test_report_{timestamp}.txt")
    with open(report_file, "w", encoding="utf-8") as f:
        f.write("=" * 80 + "\n")
        f.write("ì²­í‚¹ í…ŒìŠ¤íŠ¸ ìƒì„¸ ë³´ê³ ì„œ\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"í…ŒìŠ¤íŠ¸ ë‚ ì§œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ë°ì´í„° íŒŒì¼: {data_file}\n")
        f.write(f"í…ŒìŠ¤íŠ¸ëœ ì•„ì´í…œ ìˆ˜: {len(chunking_results)}ê°œ\n")
        f.write(f"ì´ ì²­í¬ ìˆ˜: {total_chunks}ê°œ\n")
        f.write(f"í…ìŠ¤íŠ¸ ì²­í¬: {total_text_chunks}ê°œ\n")
        f.write(f"í‘œ ì²­í¬: {total_table_chunks}ê°œ\n\n")
        f.write("=" * 80 + "\n\n")
        
        for item_idx, result in enumerate(chunking_results, 1):
            f.write(f"\n[{item_idx}] {result['title']}\n")
            f.write(f"ì§€ì—­: {result['region']}\n")
            f.write(f"ì›ë³¸ ê¸¸ì´: {result['original_length']:,}ì\n")
            f.write(f"ì²­í¬ ìˆ˜: {result['chunk_count']}ê°œ\n")
            f.write(f"URL: {result['source_url']}\n")
            f.write("-" * 80 + "\n\n")
            
            for chunk in result['chunks']:
                f.write(f"  [ì²­í¬ {chunk['chunk_number']}] ({chunk['type']}, {chunk['length']:,}ì)\n")
                f.write("  " + "-" * 76 + "\n")
                # ì²­í¬ ë‚´ìš©ì„ ë“¤ì—¬ì“°ê¸°ë¡œ ì¶œë ¥
                for line in chunk['content'].split('\n'):
                    f.write(f"  {line}\n")
                f.write("\n")
    
    print(f"ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: {report_file}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ì²­í‚¹ í…ŒìŠ¤íŠ¸ - split_text_with_tables í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"
    )
    parser.add_argument(
        "--data-file",
        type=str,
        default=None,
        help=f"í…ŒìŠ¤íŠ¸í•  JSON ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: {DEFAULT_DATA_FILE})"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help=f"ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: {DEFAULT_OUTPUT_DIR})"
    )
    parser.add_argument(
        "--max-items",
        type=int,
        default=5,
        help="í…ŒìŠ¤íŠ¸í•  ìµœëŒ€ ì•„ì´í…œ ìˆ˜ (ê¸°ë³¸ê°’: 5)"
    )
    
    args = parser.parse_args()
    
    try:
        test_chunking(
            data_file=args.data_file,
            output_dir=args.output_dir,
            max_items=args.max_items
        )
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

