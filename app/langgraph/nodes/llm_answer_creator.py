# llm_answer_creator.py (Gemini Version)
# ëª©ì : "Answer LLM" ë…¸ë“œ
# - RetrievalPlannerì˜ ê²°ê³¼ë¥¼ ë°›ì•„ ìµœì¢… ë‹µë³€ ìƒì„±
# - Google Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±

from __future__ import annotations

import json
import os
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
import google.generativeai as genai

from app.langgraph.state.ephemeral_context import State as GraphState, Message

load_dotenv()

# Gemini API ì„¤ì •
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
ANSWER_MODEL = os.getenv("ANSWER_MODEL", "gemini-2.0-flash")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SYSTEM PROMPT (ì»¬ë ‰ì…˜ ê³„ì¸µ L0/L1/L2 ë°˜ì˜ ë²„ì „)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì˜ë£ŒÂ·ë³µì§€ ì •ì±… ì¶”ì²œ ìƒë‹´ì‚¬ì´ë‹¤.

ì…ë ¥ìœ¼ë¡œ ë‹¤ìŒ ì •ë³´ê°€ ì£¼ì–´ì§„ë‹¤:
- ì‚¬ìš©ì ì§ˆë¬¸ (í˜„ì¬ í„´ì˜ user_input)
- Profile ì»¨í…ìŠ¤íŠ¸:
  - ì´ë¯¸ RAG ë‹¨ê³„ì—ì„œ ì§€ì—­, ì†Œë“(ì¤‘ìœ„ì†Œë“ ë¹„ìœ¨), ê¸°ì´ˆìƒí™œë³´ì¥, ì¥ì• ë“±ê¸‰, ì¥ê¸°ìš”ì–‘ë“±ê¸‰ ë“±ì˜
    **í•˜ë“œ í•„í„°ë§ì— ì‚¬ìš©ë˜ì—ˆë‹¤.**
- Collection ê³„ì¸µ ì»¨í…ìŠ¤íŠ¸(collection_layers):
  - L0: ì´ë²ˆ í„´ì—ì„œ ìƒˆë¡œ ì¶”ì¶œëœ ì§ˆí™˜Â·ì¹˜ë£ŒÂ·ì—í”¼ì†Œë“œ ì •ë³´ (ê°€ì¥ ì¤‘ìš”)
  - L1: ì´ë²ˆ ì„¸ì…˜ ë™ì•ˆ ëˆ„ì ëœ ì§ˆí™˜Â·ì¹˜ë£Œ ì •ë³´
  - L2: ê³¼ê±°(DB)ì— ì €ì¥ëœ ì§ˆí™˜Â·ì¹˜ë£Œ ì •ë³´ (ê°€ì¥ ë‚®ì€ ì¤‘ìš”ë„)
- RAG ë¬¸ì„œ ìŠ¤ë‹ˆí« ëª©ë¡:
  - ê° ì •ì±…ì˜ ì œëª©(title), ì‹ ì²­ ìš”ê±´(requirements), ì§€ì› ë‚´ìš©(benefits), ì§€ì—­(region), URL ë“±

ì¤‘ìš”:
1) **ì •ì±… í›„ë³´ì˜ 1ì°¨ ì„ ë³„ê³¼ í•„í„°ë§ì€ ì´ë¯¸ ëë‚œ ìƒíƒœ**ì´ë‹¤.
   - ì§€ì—­/ì†Œë“/ì¥ì• /ì¥ê¸°ìš”ì–‘/ê¸°ì´ˆìƒí™œë³´ì¥ ë“±ì˜ ê¸°ë³¸ ìê²©ì€
     profile ê¸°ë°˜ í•˜ë“œ í•„í„°ë§ì—ì„œ ì´ë¯¸ ë°˜ì˜ë˜ì—ˆë‹¤.
2) ë‹¹ì‹ ì€ ì´ í›„ë³´ë“¤ ì‚¬ì´ì—ì„œ,
   **â€œì‚¬ìš©ìì˜ Collection(ì§ˆí™˜Â·ì¹˜ë£ŒÂ·ì—í”¼ì†Œë“œ)ê³¼ ì–¼ë§ˆë‚˜ ì˜ ë§ëŠ”ê°€â€ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ**
   ì í•©ì„±ì„ í‰ê°€í•˜ê³  ì„¤ëª…í•´ì•¼ í•œë‹¤.
3) íŠ¹íˆ Collection ê³„ì¸µì˜ ì¤‘ìš”ë„ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:
   - L0 (ì´ë²ˆ í„´ ì •ë³´) â†’ ê°€ì¥ ê°•í•˜ê²Œ ë°˜ì˜
   - L1 (ì´ë²ˆ ì„¸ì…˜ ëˆ„ì  ì •ë³´) â†’ ê·¸ ë‹¤ìŒìœ¼ë¡œ ë°˜ì˜
   - L2 (ê³¼ê±° DB ì •ë³´) â†’ ë¶€ê°€ì ì¸ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ë‚´ë¶€ íŒë‹¨ ê·œì¹™ â€“ ì»¬ë ‰ì…˜ ì¤‘ì‹¬ + ê³„ì¸µ ë°˜ì˜]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ ë¶€ë¶„ì€ ë‹µë³€ì— ê·¸ëŒ€ë¡œ ì“°ì§€ ë§ê³ , ë¨¸ë¦¿ì†ì—ì„œë§Œ ìˆ˜í–‰í•˜ë¼.

1. ì‚¬ìš©ì Collection ì´í•´
   - L0, L1, L2 ë ˆì´ì–´ë¥¼ ì°¨ë¡€ë¡œ ë³´ë©´ì„œ ì •ë¦¬í•œë‹¤:
     - ì–´ë–¤ ì§ˆí™˜(ì˜ˆ: ì•”, ìœ ë°©ì•”, ì·Œì¥ì•”, ë‹¹ë‡¨, í¬ê·€ì§ˆí™˜ ë“±)ì„ ê°€ì§€ê³  ìˆëŠ”ì§€
     - ì–´ë–¤ ì¹˜ë£Œ(í•­ì•”ì¹˜ë£Œ, íˆ¬ì„, ìˆ˜ìˆ , ì…ì›, ì¬í™œ ë“±)ë¥¼ ë°›ê³  ìˆëŠ”ì§€
     - ì„ì‹  ì—¬ë¶€/ê¸°ê°„ ë“±
   - íŒë‹¨ ì‹œ:
     - L0ì— ìˆëŠ” ì •ë³´ëŠ” â€œí˜„ì¬ ì‚¬ìš©ìê°€ íŠ¹íˆ ì¤‘ìš”í•˜ê²Œ ë§í•œ ìƒíƒœâ€ë¼ê³  ë³´ê³ 
       ì •ì±… ì í•©ì„± í‰ê°€ì—ì„œ ê°€ì¥ í° ë¹„ì¤‘ì„ ë‘”ë‹¤.
     - L1ì€ â€œì´ë²ˆ ì„¸ì…˜ ë‚´ë‚´ ìœ ì§€ë˜ëŠ” ìƒíƒœ/ì „ì œâ€ë¡œì„œ ì¤‘ê°„ ì •ë„ ë¹„ì¤‘.
     - L2ëŠ” â€œì˜›ë‚  ì •ë³´ ë˜ëŠ” ë¶€ê°€ ì •ë³´â€ë¡œì„œ ë‚®ì€ ë¹„ì¤‘ìœ¼ë¡œ ì°¸ê³ í•œë‹¤.

2. ê° ì •ì±… í›„ë³´ì— ëŒ€í•´ ë‹¤ìŒì„ ë³¸ë‹¤:
   - ì •ì±…ì˜ ì‹ ì²­ ìš”ê±´(requirements)ê³¼ ì§€ì› ë‚´ìš©(benefits)ì—
     - L0/L1/L2ì˜ ì§ˆí™˜, ì¹˜ë£Œ, ìƒíƒœê°€ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰ë˜ê±°ë‚˜
       ê°•í•˜ê²Œ ì—°ê´€ë˜ëŠ”ì§€ ì‚´í´ë³¸ë‹¤.
     - ì˜ˆ:
       - L0: "ì·Œì¥ì•”, í•­ì•”ì¹˜ë£Œ ì¤‘"
       - ì •ì±… ìš”ê±´: "ì•” í™˜ì ì˜ë£Œë¹„ ì§€ì›", "í•­ì•”ì¹˜ë£Œ ì¤‘ ì•” í™˜ì", "í¬ê·€Â·ë‚œì¹˜ì„± ì§ˆí™˜ì"
     - ì´ëŸ° ê²½ìš° **ì í•©ì„±ì´ ë§¤ìš° ë†’ë‹¤**ê³  íŒë‹¨í•œë‹¤ (íŠ¹íˆ L0 ê¸°ë°˜ì´ë©´ ë” ê°•í•˜ê²Œ).

3. í”„ë¡œí•„(Profile) ì •ë³´ëŠ” ì–´ë–»ê²Œ ì“°ëŠ”ê°€?
   - ì§€ì—­/ì†Œë“/ì¥ì•  ë“±ì€ **ì´ë¯¸ í•„í„°ë§ì— ì‚¬ìš©ë˜ì—ˆìœ¼ë¯€ë¡œ**
     ë” ì´ìƒ â€œë ì§€/ì•ˆ ë ì§€â€ë¥¼ ë”°ì§€ëŠ” íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ë§ë¼.
   - ë‹¨, ì„¤ëª…ì„ í•  ë•Œ
     - â€œì´ë¯¸ ì¤‘ìœ„ì†Œë“, ì§€ì—­ ë“± ê¸°ë³¸ ìê²©ì€ ì‹œìŠ¤í…œì—ì„œ ê±¸ëŸ¬ì§„ ìƒíƒœì…ë‹ˆë‹¤.â€ì²˜ëŸ¼
       ë¶€ì—° ì„¤ëª… ì •ë„ë¡œ í™œìš©í•  ìˆ˜ëŠ” ìˆë‹¤.
   - í•˜ì§€ë§Œ,
     - â€œì†Œë“ì´ ì¡°ê¸ˆ ë†’ì•„ì„œ ì•ˆ ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.â€,
     - â€œì§€ì—­ì´ ë‹¬ë¼ì„œ ëŒ€ìƒì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.â€
     ê°™ì€ ì‹ìœ¼ë¡œ **ì¶”ê°€ë¡œ íƒˆë½ì‹œí‚¤ê±°ë‚˜ ë¶ˆì´ìµ íŒë‹¨ì„ í•˜ì§€ ë§ë¼.**

4. ìµœì¢… ì„ íƒ
   - Collection(íŠ¹íˆ L0)ê³¼ì˜ ê´€ë ¨ì„±ì´ ë†’ì€ ì •ì±…ë¶€í„° ë‚´ë¶€ì ìœ¼ë¡œ ìˆœì„œë¥¼ ì •í•œë‹¤.
   - ë³´í†µ ìƒìœ„ 3~5ê°œ ì •ì±…ë§Œ ì‚¬ìš©ìì—ê²Œ ìì„¸íˆ ë³´ì—¬ì¤€ë‹¤.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[ì¶œë ¥ í˜•ì‹ â€“ ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ì§€ì¼œë¼]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1) ë§¨ ì•ì— í•œ ì¤„ ì •ë„ì˜ ì „ì²´ ìš”ì•½ (ì„ íƒ ì‚¬í•­)
   - ì˜ˆ: "í˜„ì¬ ì •ë³´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³¼ ë•Œ, ì•„ë˜ ì •ì±…ë“¤ì´ ì‚¬ìš©ìì˜ ì§ˆí™˜/ì¹˜ë£Œ ìƒí™©ê³¼ ê´€ë ¨ì„±ì´ ë†’ìŠµë‹ˆë‹¤."

2) ì´í›„, ê° ì •ì±…ì— ëŒ€í•´ **ì•„ë˜ 4ì¤„ í˜•ì‹**ìœ¼ë¡œë§Œ ì¶œë ¥í•œë‹¤.
   - ì •ì±…ëª…, ì¡°ê±´, í˜œíƒì€ **ë¬¸ì„œì—ì„œ ì˜¨ ë¬¸ìì—´ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©**í•´ì•¼ í•œë‹¤.
   - ì¤„ ìˆœì„œì™€ ë¼ë²¨ì„ ì •í™•íˆ ì§€ì¼œë¼.

ê° ì •ì±…ì— ëŒ€í•´ ë‹¤ìŒ í¬ë§·ì„ ë°˜ë³µí•˜ë¼:

ì •ì±…ëª…: {ì •ì±… ì œëª©ì„ ê·¸ëŒ€ë¡œ ì ê¸°}
ì¡°ê±´: {í•´ë‹¹ ì •ì±…ì˜ ì‹ ì²­ ìš”ê±´(requirements)ì„ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì ê¸°}
í˜œíƒ: {í•´ë‹¹ ì •ì±…ì˜ ì§€ì› ë‚´ìš©(benefits)ì„ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì ê¸°}
ì í•©ì„±: {ì´ ì •ì±…ì´ ì‚¬ìš©ì Collection/ì§ˆí™˜/ì¹˜ë£Œì™€ ì–´ë–»ê²Œ ê´€ë ¨ë˜ëŠ”ì§€ í•œêµ­ì–´ë¡œ ì„¤ëª…}

í˜•ì‹ ê·œì¹™:
- "ì •ì±…ëª…:", "ì¡°ê±´:", "í˜œíƒ:", "ì í•©ì„±:" ì´ë¼ëŠ” í•œê¸€ ë¼ë²¨ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë¼.
- ì •ì±…ëª…/ì¡°ê±´/í˜œíƒ ë¶€ë¶„ì—ì„œëŠ” **ìš”ì•½í•˜ê±°ë‚˜ ë°”ê¾¸ì§€ ë§ê³ **, ì…ë ¥ìœ¼ë¡œ ë°›ì€ ë¬¸ìì—´ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤.
  - ë‹¨, ì–‘ìª½ ê³µë°± ì œê±° ì •ë„ë§Œ í—ˆìš©ëœë‹¤.
- ì í•©ì„± ë¶€ë¶„ì—ì„œë§Œ ìì—°ì–´ ì„¤ëª…ì„ í•œë‹¤.
  - ì—¬ê¸°ì—ì„œ Collection ê³„ì¸µ(L0/L1/L2)ì„ í™œìš©í•´
    ì™œ ì´ ì •ì±…ì´ ì‚¬ìš©ìì—ê²Œ ì˜ë¯¸ê°€ ìˆëŠ”ì§€, ì–´ë–¤ ê³„ì¸µ ì •ë³´ê°€ íŠ¹íˆ ì¤‘ìš”í•œì§€ ì„¤ëª…í•˜ë¼.
    ì˜ˆ: "ì´ë²ˆ í„´(L0)ì—ì„œ ì–¸ê¸‰í•˜ì‹  'ì·Œì¥ì•” í•­ì•”ì¹˜ë£Œ ì¤‘' ìƒíƒœê°€ ì´ ì •ì±…ì˜ 'ì•” í™˜ì' ìš”ê±´ê³¼ ì§ì ‘ì ìœ¼ë¡œ ì¼ì¹˜í•©ë‹ˆë‹¤."
    ì˜ˆ: "ê³¼ê±°(DB, L2) ê¸°ë¡ì— 'ë‹¹ë‡¨' ì§„ë‹¨ì´ ìˆìœ¼ë‚˜, ì´ë²ˆ ì§ˆì˜ì—ì„œëŠ” ë‹¤ë¥¸ ì§ˆí™˜ì´ ì¤‘ì‹¬ì´ë¯€ë¡œ ìš°ì„ ìˆœìœ„ëŠ” ë‹¤ì†Œ ë‚®ìŠµë‹ˆë‹¤."

- ì •ì±…ë“¤ ì‚¬ì´ì—ëŠ” ë¹ˆ ì¤„ í•œ ì¤„ì„ ë‘ì–´ êµ¬ë¶„í•˜ë¼.

3) ì£¼ì˜ ì‚¬í•­
- ìƒˆë¡œìš´ ì •ì±…ëª…Â·ì œë„ëª…ì„ ë§Œë“¤ì–´ë‚´ì§€ ë§ë¼.
  - **ë°˜ë“œì‹œ RAGë¡œ ì œê³µëœ ì •ì±… ì œëª©ë§Œ** ì‚¬ìš©í•˜ë¼.
- ì¡°ê±´/í˜œíƒ ë¬¸ì¥ì„ ìš”ì•½í•˜ê±°ë‚˜ ì¬êµ¬ì„±í•˜ì§€ ë§ ê²ƒ.
- ì†Œë“/ì§€ì—­/ì¥ì•  ë“± í”„ë¡œí•„ ì •ë³´ë¡œ â€œë˜ í•œ ë²ˆ íƒˆë½ íŒë‹¨â€ì„ í•˜ì§€ ë§ê³ ,
  ì´ë¯¸ í•„í„°ë§ëœ í›„ë³´ë¼ëŠ” ì „ì œì—ì„œ
  **Collectionê³¼ì˜ ê´€ë ¨ì„± ì„¤ëª…ì— ì§‘ì¤‘í•˜ë¼.**
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì»¨í…ìŠ¤íŠ¸ ìš”ì•½/ì„œì‹í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _format_profile_ctx(p: Optional[Dict[str, Any]]) -> str:
    if not p or "error" in p:
        return ""
    lines: List[str] = []

    if p.get("summary"):
        lines.append(f"- ìš”ì•½: {p['summary']}")

    if p.get("insurance_type"):
        lines.append(f"- ê±´ë³´ ìê²©: {p['insurance_type']}")

    mir_raw = p.get("median_income_ratio")
    if mir_raw is not None:
        try:
            v = float(mir_raw)
            if v <= 10:
                pct = v * 100.0
            else:
                pct = v
            lines.append(f"- ì¤‘ìœ„ì†Œë“ ë¹„ìœ¨: {pct:.1f}%")
        except:  # noqa: E722
            lines.append(f"- ì¤‘ìœ„ì†Œë“ ë¹„ìœ¨: {mir_raw}")

    if (bb := p.get("basic_benefit_type")):
        lines.append(f"- ê¸°ì´ˆìƒí™œë³´ì¥: {bb}")

    if (dg := p.get("disability_grade")) is not None:
        dg_label = {0: "ë¯¸ë“±ë¡", 1: "ì‹¬í•œ", 2: "ì‹¬í•˜ì§€ì•ŠìŒ"}.get(dg, str(dg))
        lines.append(f"- ì¥ì•  ë“±ê¸‰: {dg_label}")

    if (lt := p.get("ltci_grade")) and lt != "NONE":
        lines.append(f"- ì¥ê¸°ìš”ì–‘ ë“±ê¸‰: {lt}")

    if p.get("pregnant_or_postpartum12m") is True:
        lines.append("- ì„ì‹ /ì¶œì‚° 12ê°œì›” ì´ë‚´")

    return "\n".join(lines)


def _format_collection_ctx(items: Optional[List[Dict[str, Any]]]) -> str:
    """
    ë‹¨ì¼ ì»¬ë ‰ì…˜(triples ë¦¬ìŠ¤íŠ¸)ì„ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½.
    (ê¸°ì¡´ flat ë¦¬ìŠ¤íŠ¸ìš© í¬ë§·)
    """
    if not items:
        return ""
    out = []
    for it in items[:8]:
        if "error" in it:
            continue
        segs = []
        if it.get("predicate"):
            segs.append(f"[{it['predicate']}]")
        if it.get("object"):
            segs.append(it["object"])
        out.append("- " + " ".join(segs))
    return "\n".join(out)


def _format_collection_layers(layers: Optional[Dict[str, Any]]) -> str:
    """
    collection_layers (L0/L1/L2)ë¥¼ ì‚¬ëŒì´ ë³´ê¸° ì¢‹ê²Œ í¬ë§·.
    - L0: ì´ë²ˆ í„´
    - L1: ì´ë²ˆ ì„¸ì…˜ ëˆ„ì 
    - L2: ê³¼ê±°(DB)
    """
    if not isinstance(layers, dict):
        return ""

    out_blocks: List[str] = []

    def _add_layer(name: str, label: str):
        layer = layers.get(name)
        if not isinstance(layer, dict):
            return
        triples = layer.get("triples")
        if not isinstance(triples, list) or not triples:
            return
        body = _format_collection_ctx(triples)
        if not body:
            return
        out_blocks.append(f"[Collection {label}]\n{body}")

    _add_layer("L0", "L0 - ì´ë²ˆ í„´ ì •ë³´")
    _add_layer("L1", "L1 - ì´ë²ˆ ì„¸ì…˜ ëˆ„ì  ì •ë³´")
    _add_layer("L2", "L2 - ê³¼ê±°(DB) ì •ë³´")

    return "\n\n".join(out_blocks)


def _format_documents(items: Optional[List[Dict[str, Any]]]) -> str:
    if not items:
        return ""
    out: List[str] = []

    for idx, doc in enumerate(items[:6], start=1):
        if not isinstance(doc, dict):
            continue

        title = doc.get("title") or doc.get("doc_id") or f"ë¬¸ì„œ {idx}"
        source = doc.get("source")
        score = doc.get("score")
        url = doc.get("url")
        snippet = doc.get("snippet") or ""

        header = f"{idx}. {title}"
        if source:
            header += f" ({source})"
        if score:
            try:
                header += f" [score={float(score):.3f}]"
            except Exception:
                header += f" [score={score}]"

        out.append(f"- {header}")
        out.append(f"  > {snippet.strip()}")

        if url:
            out.append(f"  ì¶œì²˜: {url}")

    return "\n".join(out)


def _build_user_prompt(
    input_text: str,
    used: str,
    profile_ctx: Optional[Dict[str, Any]],
    collection_layers: Optional[Dict[str, Any]],
    summary: Optional[str] = None,
    documents: Optional[List[Dict[str, Any]]] = None,
) -> str:
    """
    Geminiì— ë„˜ê¸¸ user prompt êµ¬ì„±.
    - collection_layers(L0/L1/L2)ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë³´ì—¬ì¤€ë‹¤.
    """
    prof_block = _format_profile_ctx(profile_ctx)
    layers_block = _format_collection_layers(collection_layers)
    doc_block = _format_documents(documents)
    summary_block = (summary or "").strip()

    lines: List[str] = [f"ì‚¬ìš©ì ì§ˆë¬¸:\n{input_text.strip()}"]
    lines.append(f"\n[Retrieval ì‚¬ìš©: {used}]")

    if prof_block:
        lines.append("\n[Profile ì»¨í…ìŠ¤íŠ¸]\n" + prof_block)
    if layers_block:
        lines.append("\n[Collection ê³„ì¸µ ì»¨í…ìŠ¤íŠ¸]\n" + layers_block)
    if summary_block:
        lines.append("\n[Rolling Summary]\n" + summary_block)
    if doc_block:
        lines.append("\n[RAG ë¬¸ì„œ ìŠ¤ë‹ˆí«]\n" + doc_block)

    # SYSTEM_PROMPTì—ì„œ ì¶œë ¥ í˜•ì‹ì„ ì´ë¯¸ ì •ì˜í–ˆìœ¼ë¯€ë¡œ
    # ì—¬ê¸°ì„œëŠ” ë³„ë„ ì¶œë ¥ í˜•ì‹ ìš”êµ¬ì‚¬í•­ì€ ë„£ì§€ ì•ŠëŠ”ë‹¤.
    return "\n".join(lines)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini LLM í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_answer_llm(
    input_text: str,
    used: str,
    profile_ctx: Optional[Dict[str, Any]],
    collection_layers: Optional[Dict[str, Any]],
    summary: Optional[str] = None,
    documents: Optional[List[Dict[str, Any]]] = None,
) -> str:

    user_prompt = _build_user_prompt(
        input_text,
        used,
        profile_ctx,
        collection_layers,
        summary=summary,
        documents=documents,
    )

    model = genai.GenerativeModel(ANSWER_MODEL)

    # Gemini 2.x ì—ì„œëŠ” system role ë¶ˆê°€ëŠ¥ â†’ system í”„ë¡¬í”„íŠ¸ë¥¼ ë¬¸ìì—´ ê²°í•©ìœ¼ë¡œ ë„£ì–´ì•¼ í•¨
    full_prompt = SYSTEM_PROMPT + "\n\n" + user_prompt

    try:
        resp = model.generate_content(
            full_prompt,
            generation_config={"temperature": 0.3},
        )

        # 1) resp.textê°€ ìˆì„ ê²½ìš°
        if hasattr(resp, "text") and resp.text:
            return resp.text.strip()

        # 2) Gemini 2.x í‘œì¤€ êµ¬ì¡°: candidates[].content.parts[].text
        if getattr(resp, "candidates", None):
            cand = resp.candidates[0]
            if getattr(cand, "content", None) and getattr(cand.content, "parts", None):
                text = "".join(
                    part.text
                    for part in cand.content.parts
                    if hasattr(part, "text")
                )
                return text.strip()

        return str(resp)

    except Exception as e:
        print("ğŸ”¥ğŸ”¥ [Gemini ERROR]", e)
        raise

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì‹œì§€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _extract_context_from_messages(messages: List[Message]) -> Dict[str, Any]:
    for msg in reversed(messages or []):
        if msg.get("role") != "tool":
            continue
        if msg.get("content") != "[context_assembler] prompt_ready":
            continue
        meta = msg.get("meta") or {}
        ctx = meta.get("context")
        if isinstance(ctx, dict):
            return ctx
    return {}


def _last_user_content(messages: List[Message]) -> str:
    for msg in reversed(messages or []):
        if msg.get("role") == "user":
            return msg.get("content", "")
    return ""


def _infer_used_flag(profile_ctx: Any, collection_ctx: Any, documents: Any) -> str:
    has_profile = isinstance(profile_ctx, dict) and bool(profile_ctx)
    has_collection = isinstance(collection_ctx, list) and bool(collection_ctx)
    has_docs = isinstance(documents, list) and bool(documents)
    if has_profile and (has_collection or has_docs):
        return "BOTH"
    if has_profile:
        return "PROFILE"
    if has_collection or has_docs:
        return "COLLECTION"
    return "NONE"


def _safe_json(value: Any, limit: int = 400) -> str:
    if not value:
        return "ì—†ìŒ"
    try:
        text = json.dumps(value, ensure_ascii=False)
    except Exception:
        text = str(value)
    return text[:limit] + ("..." if len(text) > limit else "")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Fallback ë©”ì‹œì§€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_fallback_text(
    used: str,
    profile_ctx: Any,
    collection_ctx: Any,
    documents: Any,
    summary: Optional[str],
) -> str:
    return (
        "ì£„ì†¡í•´ìš”. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.\n\n"
        "## ê·¼ê±°(ìš”ì•½)\n"
        f"- Retrieval ì‚¬ìš©: {used}\n"
        f"- Summary: {(summary or 'ì—†ìŒ')[:400]}\n"
        f"- Profile: {_safe_json(profile_ctx)}\n"
        f"- Collection: {_safe_json(collection_ctx)}\n"
        f"- Documents: {_safe_json(documents)}\n"
        "í•„ìš” ì‹œ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ answer ë…¸ë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def answer(state: GraphState) -> Dict[str, Any]:
    messages: List[Message] = list(state.get("messages") or [])
    retrieval = state.get("retrieval") or {}
    ctx = _extract_context_from_messages(messages)

    profile_ctx = ctx.get("profile") or retrieval.get("profile_ctx")
    collection_ctx = ctx.get("collection") or retrieval.get("collection_ctx")

    # flat ë¦¬ìŠ¤íŠ¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€: fallback/used flagìš©)
    if isinstance(collection_ctx, dict) and "triples" in collection_ctx:
        collection_ctx_list = collection_ctx["triples"]
    elif isinstance(collection_ctx, list):
        collection_ctx_list = collection_ctx
    else:
        collection_ctx_list = None

    documents = ctx.get("documents") or retrieval.get("rag_snippets")
    summary = ctx.get("summary") or state.get("rolling_summary")

    input_text = (
        (state.get("user_input") or state.get("input_text") or "").strip()
        or _last_user_content(messages).strip()
    )

    # collection_layers: context â†’ retrieval â†’ state ìˆœìœ¼ë¡œ ì¡°íšŒ
    collection_layers = (
        ctx.get("collection_layers")
        or retrieval.get("collection_layers")
        or {
            "L0": state.get("collection_layer_L0"),
            "L1": state.get("collection_layer_L1"),
            "L2": state.get("collection_layer_L2"),
        }
    )

    used = (retrieval.get("used") or "").strip().upper()
    if not used:
        used = _infer_used_flag(profile_ctx, collection_ctx_list, documents)

    try:
        text = run_answer_llm(
            input_text,
            used,
            profile_ctx,
            collection_layers,
            summary=summary,
            documents=documents,
        )
    except Exception:
        text = _build_fallback_text(
            used,
            profile_ctx,
            collection_ctx_list,
            documents,
            summary,
        )

    citations = {
        "profile": profile_ctx,
        "collection": collection_ctx_list,
        "documents": documents,
    }

    assistant_message: Message = {
        "role": "assistant",
        "content": text,
        "created_at": datetime.now(timezone.utc).isoformat(),
        "meta": {
            "model": ANSWER_MODEL,
            "used": used,
            "citations": {
                "profile": bool(profile_ctx),
                "collection_count": len(collection_ctx_list or []),
                "document_count": len(documents or []),
            },
        },
    }

    return {
        "answer": {
            "text": text,
            "citations": citations,
            "used": used,
        },
        "messages": [assistant_message],
    }


def answer_llm_node(state: GraphState) -> Dict[str, Any]:
    return answer(state)
